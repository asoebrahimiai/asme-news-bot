import os
import requests
from bs4 import BeautifulSoup
from appwrite.client import Client
from appwrite.services.databases import Databases
from appwrite.id import ID
from appwrite.query import Query
from datetime import datetime, timezone
import time
import re
from newspaper import Article, Config
import google.generativeai as genai

# â”€â”€â”€ Environment Variables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TELEGRAM_TOKEN    = os.environ.get("TELEGRAM_TOKEN", "")
TELEGRAM_CHANNEL  = os.environ.get("TELEGRAM_CHANNEL", "")
APPWRITE_ENDPOINT   = os.environ.get("APPWRITE_ENDPOINT", "https://cloud.appwrite.io/v1")
APPWRITE_PROJECT_ID = os.environ.get("APPWRITE_PROJECT_ID", "")
APPWRITE_API_KEY    = os.environ.get("APPWRITE_API_KEY", "")
DATABASE_ID       = os.environ.get("APPWRITE_DATABASE_ID", "")
COLLECTION_ID     = os.environ.get("APPWRITE_COLLECTION_ID", "")
GEMINI_API_KEY    = os.environ.get("GEMINI_API_KEY", "")

HEADLINES_URL = "https://www.asme.org/about-asme/media-inquiries/asme-in-the-headlines"
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

# â”€â”€â”€ Helper Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def escape_markdown(text: str) -> str:
    """Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø§ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø±Ø²Ø±Ùˆ Ø´Ø¯Ù‡ Ø¯Ø± Markdown"""
    parse_chars = r'_*[]()~`>#+-=|{}.!'
    return re.sub(f'([{re.escape(parse_chars)}])', r'\\\1', text)

# â”€â”€â”€ Appwrite Database Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_db():
    client = Client()
    client.set_endpoint(APPWRITE_ENDPOINT)
    client.set_project(APPWRITE_PROJECT_ID)
    client.set_key(APPWRITE_API_KEY)
    return Databases(client)

def is_published(databases, url: str) -> bool:
    try:
        res = databases.list_documents(
            database_id=DATABASE_ID,
            collection_id=COLLECTION_ID,
            queries=[Query.equal("news_url", [url])]
        )
        return res["total"] > 0
    except Exception as e:
        print(f"Error checking DB: {e}")
        return False

def save_to_db(databases, url: str, title: str):
    try:
        databases.create_document(
            database_id=DATABASE_ID,
            collection_id=COLLECTION_ID,
            document_id=ID.unique(),
            data={
                "news_url": url,
                "title": title[:255], # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø·ÙˆÙ„ Ø±Ø´ØªÙ‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
                "published_at": datetime.now(timezone.utc).isoformat()
            }
        )
    except Exception as e:
        print(f"Error saving to DB: {e}")

# â”€â”€â”€ News Fetching â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_headlines() -> list:
    print(f"Fetching from: {HEADLINES_URL}")
    try:
        resp = requests.get(HEADLINES_URL, headers=HEADERS, timeout=25)
        resp.raise_for_status()
    except Exception as e:
        print(f"Network error: {e}")
        return []

    soup = BeautifulSoup(resp.content, "html.parser")
    news_list = []
    
    # Ø¬Ø³ØªØ¬ÙˆÛŒ Ú¯Ø³ØªØ±Ø¯Ù‡â€ŒØªØ± Ø¯Ø± ØµÙˆØ±Øª ØªØºÛŒÛŒØ± Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø³Ø§ÛŒØª
    content_area = soup.find('div', class_='sf_colsIn') or soup.find('main') or soup.body

    for a_tag in content_area.find_all("a", href=True):
        href = a_tag["href"].strip()
        title = a_tag.get_text(strip=True)

        # ØªØ¨Ø¯ÛŒÙ„ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù†Ø³Ø¨ÛŒ Ø¨Ù‡ Ú©Ø§Ù…Ù„
        if href.startswith('/'):
            href = "https://www.asme.org" + href
        
        # Ø§ØµÙ„Ø§Ø­ ÙÛŒÙ„ØªØ±: Ø§Ø¬Ø§Ø²Ù‡ Ø¯Ø§Ø¯Ù† Ø¨Ù‡ Ø§Ø®Ø¨Ø§Ø± Ø®Ø§Ø±Ø¬ÛŒ Ùˆ Ø¯Ø§Ø®Ù„ÛŒ Ù…Ø¹ØªØ¨Ø±
        if not href.startswith("http") or len(title) < 15:
            continue
            
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù†Ø¨Ø¹ Ø§Ø² Ù…ØªÙ† ÙˆØ§Ù„Ø¯
        source = "ASME News"
        parent = a_tag.find_parent(['p', 'div', 'li'])
        if parent:
            raw_text = parent.get_text(" ", strip=True)
            if "â€“" in raw_text:
                source = raw_text.split("â€“")[0].strip()
            elif "-" in raw_text:
                source = raw_text.split("-")[0].strip()

        if not any(d['url'] == href for d in news_list):
            news_list.append({"url": href, "title": title, "source": source})

    print(f"Found {len(news_list)} potential headlines.")
    return news_list[:5]

# â”€â”€â”€ Article Extraction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_article_text(url: str) -> str:
    try:
        config = Config()
        config.browser_user_agent = HEADERS['User-Agent']
        config.request_timeout = 15
        article = Article(url, config=config)
        article.download()
        article.parse()
        return article.text
    except Exception as e:
        print(f"Extraction failed for {url}: {e}")
        return ""

# â”€â”€â”€ AI Processing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def summarize_and_translate_with_gemini(title: str, article_text: str) -> tuple[str, str]:
    if not GEMINI_API_KEY: return title, "Error: No API Key"
    
    genai.configure(api_key=GEMINI_API_KEY)
    prompt = f """
    You are a professional journalist.
    1. Translate this title to Persian: "{title}"
    2. Summarize this text in 2 concise Persian paragraphs: "{article_text[:3500]}"
    Format:
    TITLE_FA: [translation]
    SUMMARY_FA: [summary]
    """
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ØªØ±
    for model_name in ["gemini-1.5-flash", "gemini-pro"]:
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            res_text = response.text
            
            t_fa = res_text.split("TITLE_FA:")[1].split("SUMMARY_FA:")[0].strip()
            s_fa = res_text.split("SUMMARY_FA:")[1].strip()
            return t_fa, s_fa
        except Exception as e:
            print(f"Gemini {model_name} failed: {e}")
            continue
    return title, "Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"

# â”€â”€â”€ Telegram Send â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def send_telegram(title_fa: str, summary_fa: str, source: str, news_url: str) -> bool:
    # Ø§ÛŒÙ…Ù†â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ Ù…Ø§Ø±Ú©â€ŒØ¯Ø§ÙˆÙ†
    safe_title = escape_markdown(title_fa)
    safe_summary = escape_markdown(summary_fa)
    safe_source = escape_markdown(source)

    caption = (
        f"*{safe_title}*\n\n"
        f"{safe_summary}\n\n"
        f"ğŸŒ *Ù…Ù†Ø¨Ø¹:* {safe_source}\n"
        f"ğŸ”— [Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø®Ø¨Ø± Ú©Ø§Ù…Ù„]({news_url})"
    )

    api_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    try:
        res = requests.post(api_url, json={
            "chat_id": TELEGRAM_CHANNEL,
            "text": caption,
            "parse_mode": "MarkdownV2", # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø³Ø®Ù‡ Û² Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø¨ÛŒØ´ØªØ±
            "disable_web_page_preview": False
        }, timeout=15)
        return res.status_code == 200
    except Exception as e:
        print(f"Telegram error: {e}")
        return False

# â”€â”€â”€ Main Logic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main(context):
    print("Execution started...")
    
    if not all([TELEGRAM_TOKEN, APPWRITE_PROJECT_ID, GEMINI_API_KEY]):
        return context.res.json({"ok": False, "error": "Missing Env Vars"})

    db = get_db()
    headlines = fetch_headlines()
    success_count = 0

    for item in headlines:
        if is_published(db, item['url']):
            continue

        text = extract_article_text(item['url'])
        if not text: continue

        t_fa, s_fa = summarize_and_translate_with_gemini(item['title'], text)
        
        if send_telegram(t_fa, s_fa, item['source'], item['url']):
            save_to_db(db, item['url'], item['title'])
            success_count += 1
            time.sleep(2)

    return context.res.json({"published": success_count})
