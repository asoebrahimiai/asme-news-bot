import os
import requests
from bs4 import BeautifulSoup
from appwrite.client import Client
from appwrite.services.databases import Databases
from appwrite.id import ID
from appwrite.query import Query
from datetime import datetime, timezone
import time
from newspaper import Article, Config
import google.generativeai as genai

# â”€â”€â”€ Environment Variables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TELEGRAM_TOKEN    = os.environ.get("TELEGRAM_TOKEN", "")
TELEGRAM_CHANNEL  = os.environ.get("TELEGRAM_CHANNEL", "")
APPWRITE_ENDPOINT   = os.environ.get("APPWRITE_ENDPOINT", "https://cloud.appwrite.io/v1")
APPWRITE_PROJECT_ID = os.environ.get("APPWRITE_PROJECT_ID", "")
APPWRITE_API_KEY    = os.environ.get("APPWRITE_API_KEY", "")
DATABASE_ID       = os.environ.get("APPWRITE_DATABASE_ID", "")
COLLECTION_ID     = os.environ.get("APPWRITE_COLLECTION_ID", "")
GEMINI_API_KEY    = os.environ.get("GEMINI_API_KEY", "") # Ú©Ù„ÛŒØ¯ API Ø¬Ø¯ÛŒØ¯

HEADLINES_URL = "https://www.asme.org/about-asme/media-inquiries/asme-in-the-headlines"

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

# â”€â”€â”€ Appwrite Database Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_db():
    client = Client()
    client.set_endpoint(APPWRITE_ENDPOINT)
    client.set_project(APPWRITE_PROJECT_ID)
    client.set_key(APPWRITE_API_KEY)
    return Databases(client)

def is_published(databases, url: str) -> bool:
    try:
        res = databases.list_documents(
            database_id=DATABASE_ID,
            collection_id=COLLECTION_ID,
            queries=[Query.equal("news_url", [url])]
        )
        return res["total"] > 0
    except Exception as e:
        print(f"Error checking if published: {e}")
        return False

def save_to_db(databases, url: str, title: str):
    try:
        databases.create_document(
            database_id=DATABASE_ID,
            collection_id=COLLECTION_ID,
            document_id=ID.unique(),
            data={
                "news_url": url,
                "title": title,
                "published_at": datetime.now(timezone.utc).isoformat()
            }
        )
    except Exception as e:
        print(f"Error saving to DB: {e}")

# â”€â”€â”€ News Fetching and Parsing (REVISED & ROBUST) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_headlines() -> list:
    """Ù„ÛŒØ³Øª Ø¹Ù†Ø§ÙˆÛŒÙ† Ùˆ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø®Ø¨Ø§Ø± Ø±Ø§ Ø¨Ø§ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯"""
    print("Fetching headlines from ASME...")
    try:
        resp = requests.get(HEADLINES_URL, headers=HEADERS, timeout=20)
        resp.raise_for_status()
    except requests.RequestException as e:
        print(f"Error fetching headlines page: {e}")
        return []

    soup = BeautifulSoup(resp.content, "html.parser")
    news_list = []
    
    content_area = soup.find('div', class_='sf_colsIn') or soup.body
    
    for a_tag in content_area.find_all("a", href=True):
        href = a_tag["href"].strip()
        title = a_tag.get_text(strip=True)

        if not href.startswith("http") or "asme.org" in href or len(title) < 20:
            continue

        source = ""
        parent_p = a_tag.find_parent('p')
        if parent_p:
            # Ø­Ø°Ù Ø¹Ù†ÙˆØ§Ù† Ùˆ ØªØ§Ø±ÛŒØ® Ùˆ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø¶Ø§ÙÙ‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ù‚ÛŒÙ‚ Ù…Ù†Ø¨Ø¹
            source_text = parent_p.get_text(" ", strip=True).replace(title, "").strip()
            source_text = source_text.split("â€“")[0].split("-")[0].strip()
            # Ù…Ù†Ø¨Ø¹ Ù†Ø¨Ø§ÛŒØ¯ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¨Ø§Ø´Ø¯
            if 2 < len(source_text) < 80:
                source = source_text

        if not any(d['url'] == href for d in news_list):
            news_list.append({"url": href, "title": title, "source": source.strip()})
            print(f"  Found: {title[:60]} | Source: {source}")

    print(f"Total unique headlines found: {len(news_list)}")
    return news_list[:5] # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ûµ Ø®Ø¨Ø± Ø¬Ø¯ÛŒØ¯

# â”€â”€â”€ Article Extraction (using Newspaper3k) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_article_text(url: str) -> str:
    """Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ù…Ù‚Ø§Ù„Ù‡ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ newspaper3k Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯"""
    print(f"Extracting text from: {url[:60]}")
    try:
        config = Config()
        config.browser_user_agent = HEADERS['User-Agent']
        config.request_timeout = 15
        
        article = Article(url, config=config)
        article.download()
        article.parse()
        
        return article.text
    except Exception as e:
        print(f"Error extracting article with newspaper3k: {e}")
        return ""

# â”€â”€â”€ AI Summarization & Translation (using Gemini) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def summarize_and_translate_with_gemini(title: str, article_text: str) -> tuple[str, str]:
    """Ù…ØªÙ† Ø±Ø§ Ø¨Ø§ Gemini Ø®Ù„Ø§ØµÙ‡ Ùˆ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ ØªØ±Ø¬Ù…Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯"""
    if not GEMINI_API_KEY:
        return title, "Ø®Ø·Ø§: Ú©Ù„ÛŒØ¯ API Ø¨Ø±Ø§ÛŒ Gemini ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª."
    
    genai.configure(api_key=GEMINI_API_KEY)

    prompt = f"""
    You are a professional news translator and summarizer.
    First, translate the following news TITLE to Persian.
    Second, summarize the following ARTICLE TEXT into one or two clear and concise Persian paragraphs.
    The summary should be neutral and informative.
    
    TITLE: "{title}"
    ARTICLE TEXT: "{article_text[:4000]}"

    Respond ONLY with the Persian translation and summary in this format:
    TITLE_FA: [Persian Title Here]
    SUMMARY_FA: [Persian Summary Here]
    """
    
    models_to_try = ["gemini-1.5-flash-latest", "gemini-1.0-pro"]
    
    for model_name in models_to_try:
        try:
            print(f"Attempting to use Gemini model: {model_name}")
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            
            # Parsing the response
            text = response.text
            title_fa = text.split("TITLE_FA:")[1].split("SUMMARY_FA:")[0].strip()
            summary_fa = text.split("SUMMARY_FA:")[1].strip()

            if title_fa and summary_fa:
                return title_fa, summary_fa
            else:
                # Ø§Ú¯Ø± Ù¾Ø§Ø³Ø® ÙØ±Ù…Øª Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± Ø±Ø§ Ù†Ø¯Ø§Ø´Øª
                raise ValueError("Invalid response format from Gemini")

        except Exception as e:
            print(f"Error with model {model_name}: {e}")
            if "API version v1beta" in str(e) or "is not found" in str(e):
                print("This model may not be available. Trying the next one.")
                continue # Ø±ÙØªÙ† Ø¨Ù‡ Ù…Ø¯Ù„ Ø¨Ø¹Ø¯ÛŒ
            return title, f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ: {str(e)[:100]}"
            
    return title, "Ø®Ø·Ø§: Ù‡ÛŒÚ†Ú©Ø¯Ø§Ù… Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¨ÙˆØ¯Ù†Ø¯."


# â”€â”€â”€ Telegram Bot Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def send_telegram(title_fa: str, summary_fa: str, source: str, news_url: str) -> bool:
    msg_parts = [f"ðŸ“° *{title_fa}*\n"]
    if summary_fa:
        msg_parts.append(f"{summary_fa}\n")
    if source:
        msg_parts.append(f"ðŸŒ *Ù…Ù†Ø¨Ø¹:* {source}")
    msg_parts.append(f"\nðŸ”— [Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø®Ø¨Ø± Ú©Ø§Ù…Ù„]({news_url})")
    msg_parts.append("\n_via ASME In the Headlines_")

    caption = "\n".join(msg_parts)

    api_base = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}"
    try:
        r = requests.post(
            f"{api_base}/sendMessage",
            json={
                "chat_id": TELEGRAM_CHANNEL,
                "text": caption,
                "parse_mode": "Markdown",
                "disable_web_page_preview": False
            },
            timeout=20
        )
        print(f"Telegram API response status: {r.status_code}")
        if r.status_code != 200:
            print(f"Telegram error details: {r.text[:200]}")
        return r.status_code == 200
    except Exception as e:
        print(f"Exception during Telegram send: {e}")
        return False

# â”€â”€â”€ Main Execution Logic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main(context):
    print("===================================")
    print(f"ASME Bot Execution Started at {datetime.now(timezone.utc)}")
    print("===================================")

    if not all([TELEGRAM_TOKEN, TELEGRAM_CHANNEL, DATABASE_ID, COLLECTION_ID, GEMINI_API_KEY]):
        error_msg = "One or more critical environment variables are not set."
        print(f"FATAL: {error_msg}")
        return context.res.json({"error": error_msg, "published": 0}, status_code=400)

    databases = get_db()
    news_list = fetch_headlines()

    if not news_list:
        print("No new headlines found to process.")
        return context.res.json({"published": 0, "message": "No headlines found"})

    new_count = 0
    log = []

    for news in news_list:
        try:
            if is_published(databases, news["url"]):
                print(f"Skipping (already published): {news['url'][:60]}")
                continue

            print(f"\n--- Processing: {news['title'][:70]} ---")

            article_text = extract_article_text(news["url"])
            
            if not article_text:
                print("  -> Could not extract article text. Skipping.")
                log.append(f"FAIL (extract): {news['title'][:40]}")
                continue

            print(f"  -> Extracted text length: {len(article_text)}")
            
            title_fa, summary_fa = summarize_and_translate_with_gemini(news["title"], article_text)
            
            print(f"  -> Translated Title: {title_fa[:60]}")
            print(f"  -> Summary Length: {len(summary_fa)}")

            ok = send_telegram(title_fa, summary_fa, news["source"], news["url"])

            if ok:
                save_to_db(databases, news["url"], news["title"])
                new_count += 1
                log.append(f"OK: {news['title'][:50]}")
                print(f"  -> Successfully published to Telegram and saved to DB.")
                time.sleep(2) # ÙØ§ØµÙ„Ù‡ Ø¨ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§
            else:
                log.append(f"FAIL (telegram): {news['title'][:40]}")
                print("  -> Failed to send message to Telegram.")

        except Exception as e:
            print(f"An unexpected error occurred in the main loop: {e}")
            log.append(f"ERROR: {str(e)[:60]}")

    print("\n===================================")
    print(f"Execution Finished. Published: {new_count}/{len(news_list)}")
    print("===================================")
    return context.res.json({
        "published": new_count,
        "total_found": len(news_list),
        "log": log
    })
