import os
import requests
from bs4 import BeautifulSoup
from appwrite.client import Client
from appwrite.services.databases import Databases
from appwrite.id import ID
from appwrite.query import Query
from datetime import datetime, timezone
import time

# Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆØ§ Ùˆ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
from newspaper import Article, Config
import google.generativeai as genai

# â”€â”€â”€ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø­ÛŒØ·ÛŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TELEGRAM_TOKEN   = os.environ.get("TELEGRAM_TOKEN", "")
TELEGRAM_CHANNEL = os.environ.get("TELEGRAM_CHANNEL", "")
APPWRITE_ENDPOINT   = os.environ.get("APPWRITE_ENDPOINT", "https://cloud.appwrite.io/v1")
APPWRITE_PROJECT_ID = os.environ.get("APPWRITE_PROJECT_ID", "")
APPWRITE_API_KEY    = os.environ.get("APPWRITE_API_KEY", "")
DATABASE_ID   = os.environ.get("APPWRITE_DATABASE_ID", "")
COLLECTION_ID = os.environ.get("APPWRITE_COLLECTION_ID", "")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "") # Ú©Ù„ÛŒØ¯ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ

# Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Gemini
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

HEADLINES_URL = "https://www.asme.org/about-asme/media-inquiries/asme-in-the-headlines"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36",
}

# â”€â”€â”€ Appwrite â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_db():
    client = Client()
    client.set_endpoint(APPWRITE_ENDPOINT)
    client.set_project(APPWRITE_PROJECT_ID)
    client.set_key(APPWRITE_API_KEY)
    return Databases(client)

def is_published(databases, url: str) -> bool:
    try:
        res = databases.list_documents(
            database_id=DATABASE_ID,
            collection_id=COLLECTION_ID,
            queries=[Query.equal("news_url", [url])]
        )
        return res["total"] > 0
    except Exception:
        return False

def save_to_db(databases, url: str, title: str):
    try:
        databases.create_document(
            database_id=DATABASE_ID,
            collection_id=COLLECTION_ID,
            document_id=ID.unique(),
            data={
                "news_url": url,
                "title": title,
                "published_at": datetime.now(timezone.utc).isoformat()
            }
        )
    except Exception as e:
        print(f"DB save error: {e}")

# â”€â”€â”€ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø§Ø®Ø¨Ø§Ø± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_headlines() -> list:
    print("Fetching headlines...")
    try:
        resp = requests.get(HEADLINES_URL, headers=HEADERS, timeout=20)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.content, "html.parser")
        news_list = []

        for a_tag in soup.find_all("a", href=True):
            href = a_tag["href"].strip()
            title = a_tag.get_text(strip=True)

            if not href.startswith("http") or "asme.org" in href or len(title) < 25:
                continue
            
            source = ""
            parent = a_tag.find_parent()
            if parent:
                for sibling in parent.find_all(string=True, recursive=False):
                    s = sibling.strip()
                    if s and s != title and len(s) > 2:
                        source = s.replace("via ", "").strip()[:80]
                        break

            news_list.append({"url": href, "title": title, "source": source})
        return news_list[:5]
    except Exception as e:
        print(f"Fetch error: {e}")
        return []

# â”€â”€â”€ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Gemini â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_ai_summary(url: str, title_en: str):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ùˆ ØªÙˆÙ„ÛŒØ¯ Ú†Ú©ÛŒØ¯Ù‡ Ùˆ ØªØ±Ø¬Ù…Ù‡ Ø¹Ù†ÙˆØ§Ù† ØªÙˆØ³Ø· Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
    try:
        config = Config()
        config.browser_user_agent = HEADERS["User-Agent"]
        article = Article(url, config=config)
        article.download()
        article.parse()
        
        full_text = article.text
        if len(full_text) < 200:
            return None, None

        # Ø·Ø±Ø§Ø­ÛŒ Ø¯Ø³ØªÙˆØ± (Prompt) Ø¨Ø±Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
        prompt = f"""
        You are a professional engineering news editor. Based on the following news article, please provide:
        1. A formal Persian translation of the Title.
        2. A concise one-paragraph summary of the news in Persian (max 100 words).
        
        Article Title: {title_en}
        Article Content: {full_text[:3000]}
        
        Format your response exactly like this:
        TITLE: [Persian Title]
        SUMMARY: [Persian Summary]
        """
        
        response = model.generate_content(prompt)
        output = response.text
        
        # ØªØ¬Ø²ÛŒÙ‡ Ù¾Ø§Ø³Ø® AI
        title_fa = output.split("TITLE:")[1].split("SUMMARY:")[0].strip()
        summary_fa = output.split("SUMMARY:")[1].strip()
        
        return title_fa, summary_fa
    except Exception as e:
        print(f"AI Error: {e}")
        return None, None

# â”€â”€â”€ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def send_telegram(title_fa: str, summary_fa: str, source: str, news_url: str) -> bool:
    message = f"ğŸ“° **{title_fa}**\n\n"
    message += f"ğŸ”¹ **Ú†Ú©ÛŒØ¯Ù‡ Ø®Ø¨Ø±:**\n{summary_fa}\n\n"
    if source:
        message += f"ğŸŒ **Ù…Ù†Ø¨Ø¹:** {source}\n"
    message += f"ğŸ”— [Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø®Ø¨Ø± Ú©Ø§Ù…Ù„]({news_url})\n"
    message += "â”€â”€â”€\n"
    message += "ğŸ†” @ASME_Persian_News"

    api_base = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}"
    try:
        r = requests.post(f"{api_base}/sendMessage", json={
            "chat_id": TELEGRAM_CHANNEL,
            "text": message,
            "parse_mode": "Markdown",
            "disable_web_page_preview": False
        }, timeout=15)
        return r.status_code == 200
    except Exception:
        return False

# â”€â”€â”€ ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main(context):
    print("=== ASME Smart Bot Started ===")
    
    if not all([TELEGRAM_TOKEN, TELEGRAM_CHANNEL, GEMINI_API_KEY]):
        return context.res.json({"error": "Config missing"}, status_code=500)

    databases = get_db()
    news_list = fetch_headlines()

    new_count = 0
    for news in reversed(news_list):
        if is_published(databases, news["url"]):
            continue

        print(f"Processing with AI: {news['title']}")
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§
        title_fa, summary_fa = get_ai_summary(news["url"], news["title"])

        if title_fa and summary_fa:
            if send_telegram(title_fa, summary_fa, news["source"], news["url"]):
                save_to_db(databases, news["url"], news["title"])
                new_count += 1
                time.sleep(4) # ÙˆÙ‚ÙÙ‡ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø³Ù¾Ù…

    return context.res.json({"published": new_count})
